{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba62e1c6",
   "metadata": {
    "id": "ba62e1c6"
   },
   "source": [
    "# üé® Stable Diffusion Inpainting Demo\n",
    "\n",
    "This notebook shows how to use Stable Diffusion to inpaint parts of an image using a mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05f6dc",
   "metadata": {
    "id": "7e05f6dc"
   },
   "source": [
    "\n",
    "## üìù Overview\n",
    "\n",
    "This notebook walks through the process of **inpainting**‚Äîmodifying specific parts of an image based on a mask and a text prompt‚Äîusing the `StableDiffusionInpaintPipeline`.\n",
    "\n",
    "You'll learn how to:\n",
    "- Load image and mask inputs\n",
    "- Apply inpainting to replace or modify image regions\n",
    "- Generate artistic edits guided by natural language prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a3b23",
   "metadata": {
    "id": "d24a3b23"
   },
   "outputs": [],
   "source": [
    "!pip install diffusers transformers accelerate safetensors Pillow matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d45cfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "22845227f03347558a1cb4c081d15497",
      "79bc8d4158bd49b5825d79f419fa06df",
      "5afb19051ec148c88eac9787f0edc183",
      "d6b942fd4eb8490c9a68233ce5bdaba5",
      "4ff53f5e0d4a4af78f914f5bff592c6b",
      "90b10ec7f09747ab95859a8d05516149",
      "3f1b3f92c5c84f7296dda5d5fb5a302c",
      "3c590a9def3941e19424d58b2cf791ea",
      "9827f134bc63409fb30a6040597ee889",
      "1e54a9b9938a4a00998eda6588843896",
      "46d8ed7c2f5649fe9566caf4579fd047"
     ]
    },
    "id": "55d45cfc",
    "outputId": "ea072cb1-9685-4adc-da09-7a3e44988429"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22845227f03347558a1cb4c081d15497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be49f05",
   "metadata": {
    "id": "3be49f05"
   },
   "source": [
    "### üñºÔ∏è Load Image and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914267f3",
   "metadata": {
    "id": "914267f3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Valid image and mask from CompVis\n",
    "url_image = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/billow926-12-Wc-Zgx6Y.png\"\n",
    "url_mask  = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/billow926-12-Wc-Zgx6Y_mask.png\"\n",
    "\n",
    "image = Image.open(requests.get(url_image, stream=True).raw).convert(\"RGB\").resize((512, 512))\n",
    "mask  = Image.open(requests.get(url_mask, stream=True).raw).convert(\"L\").resize((512, 512))\n",
    "\n",
    "image.save(\"inpainting_input.png\")\n",
    "mask.save(\"inpainting_mask.png\")\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d491ab69",
   "metadata": {
    "id": "d491ab69"
   },
   "source": [
    "### üß† Run Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207113e",
   "metadata": {
    "id": "2207113e"
   },
   "outputs": [],
   "source": [
    "prompt = \"A beautiful green landscape replacing the masked area\"\n",
    "output = pipe(prompt=prompt, image=image, mask_image=mask).images[0]\n",
    "output.save(\"inpainting_output.png\")\n",
    "\n",
    "plt.imshow(output)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fa3c9",
   "metadata": {
    "id": "019fa3c9"
   },
   "source": [
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "You‚Äôve learned how to use inpainting to fill in or modify parts of an image using Stable Diffusion and masks. This is a powerful way to create content-aware edits or enhancements.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
